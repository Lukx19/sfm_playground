{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import pycolmap\n",
    "import poselib\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy.typing as npt\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import visualizations as viz\n",
    "from nptyping import NDArray, Int, Shape, Float16\n",
    "\n",
    "datasetFolder =  os.path.join(\"..\", \"data\", \"captured_2022_08_27_19_28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCVImage(image: cv2.Mat):\n",
    "    plt.figure(figsize=(80, 8))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # as opencv loads in BGR format by default, we want to show it in RGB.\n",
    "    plt.show()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "def visualizeMatches(img1, keyp1, img2, keyp2, matches):\n",
    "    img1_color = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    img2_color = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    draw_params = dict(\n",
    "        # matchColor=(0, 255, 0),\n",
    "        # singlePointColor=(255, 0, 0),\n",
    "        flags=cv2.DrawMatchesFlags_DEFAULT,\n",
    "    )\n",
    "    img3 = cv2.drawMatches(\n",
    "        img1_color, keyp1, img2_color, keyp2, matches, None, **draw_params\n",
    "    )\n",
    "    plotCVImage(img3)\n",
    "\n",
    "\n",
    "\n",
    "def PlotCameras(\n",
    "    camsR: List[NDArray[Shape[\"3, 3\"], Float16]],\n",
    "    camsTrans: List[NDArray[Shape[\"3, 1\"], Float16]],\n",
    "):\n",
    "    fig = plt.figure(figsize=(80, 8))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    for R, t in zip(camsR, camsTrans):\n",
    "        viz.PlotCamera(R, t.squeeze(), ax)\n",
    "\n",
    "\n",
    "def plotCVImagesHorizontal(images, addHorizontalLines = False):\n",
    "    h_img = cv2.hconcat(images)\n",
    "    h_img = cv2.cvtColor(h_img, cv2.COLOR_BGR2RGB)\n",
    "    if addHorizontalLines:\n",
    "        colors = [(255,0,0), (0,255,0), (255, 165, 0)]\n",
    "\n",
    "        height = h_img.shape[0]\n",
    "        width = h_img.shape[1]\n",
    "        for i, y in enumerate(range(0, height, int(np.floor(height / 20)))):\n",
    "            cv2.line(h_img, (0, y), (width, y), colors[i % len(colors)], thickness=2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(180, 20))\n",
    "    ax.imshow(h_img, interpolation='bilinear')\n",
    "    plt.tight_layout()\n",
    "    # plt.imshow(h_img)\n",
    "    # plt.figure(figsize=(160, 80))\n",
    "    # # as opencv loads in BGR format by default, we want to show it in RGB.\n",
    "    # plt.show()\n",
    "    # plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypopsift import popsift\n",
    "\n",
    "# # causes segfault do not use\n",
    "# def extractPopSiftFeatures(filename: os.path):\n",
    "#     config = {\n",
    "#         \"sift_peak_threshold\": 0.1,\n",
    "#         \"sift_edge_threshold\": 10.0,\n",
    "#         \"feature_min_frames\": 8000,\n",
    "#         \"feature_use_adaptive_suppression\": False,\n",
    "#     }\n",
    "\n",
    "#     image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#     if image is None:\n",
    "#         raise IOError(\"Unable to load image {}\".format(filename))\n",
    "\n",
    "#     print(image.shape)\n",
    "\n",
    "#     points, desc = popsift(\n",
    "#         image.astype(np.uint8),  # values between 0, 1\n",
    "#         peak_threshold=config[\"sift_peak_threshold\"],\n",
    "#         edge_threshold=config[\"sift_edge_threshold\"],\n",
    "#         target_num_features=config[\"feature_min_frames\"],\n",
    "#     )\n",
    "\n",
    "#     print(points.shape)\n",
    "#     print(points)\n",
    "#     print(desc.shape)\n",
    "#     print(desc)\n",
    "\n",
    "\n",
    "# extractPopSiftFeatures(os.path.join(datasetFolder, \"1604_left.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCVSiftFeatures(\n",
    "    img: cv2.Mat,\n",
    ") -> Tuple[List[cv2.KeyPoint], npt.NDArray[np.float64]]:\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    keypoints, desc = sift.detectAndCompute(img, None)\n",
    "\n",
    "    img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    plotCVImage(\n",
    "        cv2.drawKeypoints(\n",
    "            img_color,\n",
    "            keypoints,\n",
    "            None,\n",
    "            (255, 0, 255),\n",
    "            flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS,\n",
    "        )\n",
    "    )\n",
    "    return keypoints, desc\n",
    "\n",
    "\n",
    "img1 = cv2.imread(\n",
    "    os.path.join(datasetFolder, \"1604_left.png\"),\n",
    "    cv2.IMREAD_GRAYSCALE,\n",
    ")\n",
    "\n",
    "features = extractCVSiftFeatures(img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "\n",
    "\n",
    "def matchSurfFlann(\n",
    "    desc1: npt.NDArray[np.float64], desc2: npt.NDArray[np.float64]\n",
    ") -> List[cv2.DMatch]:\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)  # or pass empty dictionary\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(desc1, desc2, k=2)\n",
    "    # Need to draw only good matches, so create a mask\n",
    "    matchesMask = [False for i in range(len(matches))]\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i, (m, n) in enumerate(matches):\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            matchesMask[i] = True\n",
    "\n",
    "    matches = map(lambda match: match[0], matches)\n",
    "    return list(compress(matches, matchesMask))\n",
    "\n",
    "\n",
    "img1 = cv2.imread(\n",
    "    os.path.join(datasetFolder, \"1604_left.png\"),\n",
    "    cv2.IMREAD_GRAYSCALE,\n",
    ")\n",
    "\n",
    "img2 = cv2.imread(\n",
    "    os.path.join(datasetFolder, \"1604_right.png\"),\n",
    "    cv2.IMREAD_GRAYSCALE,\n",
    ")\n",
    "\n",
    "kp1, desc1 = extractCVSiftFeatures(img1)\n",
    "\n",
    "kp2, desc2 = extractCVSiftFeatures(img2)\n",
    "\n",
    "matches = matchSurfFlann(desc1, desc2)\n",
    "print(\"matches:\", len(matches))\n",
    "visualizeMatches(img1, kp1, img2, kp2, matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datasetFolder, \"calibration.json\")) as json_file:\n",
    "    calibrationCam = json.load(json_file)\n",
    "\n",
    "calibrationLeft = calibrationCam[\"cameraData\"][0][1]\n",
    "calibrationRight = calibrationCam[\"cameraData\"][1][1]\n",
    "rectifiedLeftHomography = np.array(\n",
    "    calibrationCam[\"stereoRectificationData\"][\"rectifiedRotationLeft\"]\n",
    ")\n",
    "rectifiedRightHomography = np.array(\n",
    "    calibrationCam[\"stereoRectificationData\"][\"rectifiedRotationRight\"]\n",
    ")\n",
    "\n",
    "print(calibrationLeft)\n",
    "print(calibrationRight)\n",
    "print(rectifiedLeftHomography)\n",
    "print(rectifiedRightHomography)\n",
    "\n",
    "\n",
    "def extractPoseLibCameraParams(calibration: Dict):\n",
    "    intrinsics = {\n",
    "        \"model\": \"OPENCV\",\n",
    "        \"width\": calibration[\"width\"],\n",
    "        \"height\": calibration[\"height\"],\n",
    "        \"params\": [\n",
    "            calibration[\"intrinsicMatrix\"][0][0],\n",
    "            calibration[\"intrinsicMatrix\"][1][1],\n",
    "            calibration[\"intrinsicMatrix\"][0][2],\n",
    "            calibration[\"intrinsicMatrix\"][1][2],\n",
    "            *calibration[\"distortionCoeff\"][0:4],\n",
    "        ],\n",
    "    }\n",
    "    return intrinsics\n",
    "\n",
    "\n",
    "cameraLeft = extractPoseLibCameraParams(calibrationLeft)\n",
    "print(cameraLeft)\n",
    "\n",
    "cameraRight = extractPoseLibCameraParams(calibrationRight)\n",
    "print(cameraRight)\n",
    "\n",
    "rightToLeftGtRot = np.array(calibrationRight[\"extrinsics\"][\"rotationMatrix\"])\n",
    "\n",
    "origTranslation = calibrationRight[\"extrinsics\"][\"translation\"]\n",
    "rightToLeftGtTrans = np.array(\n",
    "    [origTranslation[\"x\"], origTranslation[\"y\"], origTranslation[\"z\"]]\n",
    ")\n",
    "\n",
    "intrinsicsLeft = np.array(calibrationLeft[\"intrinsicMatrix\"])\n",
    "intrinsicsRight = np.array(calibrationRight[\"intrinsicMatrix\"])\n",
    "distortionLeft = np.array(calibrationLeft[\"distortionCoeff\"])\n",
    "distortionRight = np.array(calibrationRight[\"distortionCoeff\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract2DMatches(matches, kp1, kp2):\n",
    "    img1Pts = [np.array(kp1[mat.queryIdx].pt).reshape(2, 1) for mat in matches]\n",
    "    img2Pts = [np.array(kp2[mat.trainIdx].pt).reshape(2, 1) for mat in matches]\n",
    "    return img1Pts, img2Pts\n",
    "\n",
    "\n",
    "img1Pts, img2Pts = extract2DMatches(matches, kp1, kp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(poselib.RansacOptions)\n",
    "relativePose: poselib.CameraPose = poselib.CameraPose()\n",
    "relativePose.R = rightToLeftGtRot\n",
    "relativePose.t = rightToLeftGtTrans\n",
    "\n",
    "print(relativePose)\n",
    "relativePoseUpdated = relativePose\n",
    "\n",
    "ransacParams = poselib.RansacOptions()\n",
    "ransacParams[\"progressive_sampling\"] = True\n",
    "ransacParams[\"max_reproj_error\"] = 1\n",
    "print(ransacParams)\n",
    "\n",
    "bundleParams = poselib.BundleOptions()\n",
    "bundleParams[\"verbose\"] = True\n",
    "bundleParams[\"max_iterations\"] = 0\n",
    "print(bundleParams)\n",
    "\n",
    "relativePoseRes = poselib.estimate_relative_pose(\n",
    "    img2Pts, img1Pts, cameraRight, cameraLeft, ransacParams, bundleParams\n",
    ")\n",
    "# print(relativePoseRes)\n",
    "relativePoseUpdated = relativePoseRes[0]\n",
    "print(relativePoseUpdated)\n",
    "\n",
    "inliers: List[bool] = relativePoseRes[1][\"inliers\"]\n",
    "inlierMatches = list(compress(matches, inliers))\n",
    "visualizeMatches(img1, kp1, img2, kp2, inlierMatches)\n",
    "\n",
    "\n",
    "relPoseR = relativePoseUpdated.R\n",
    "relPoseTr = relativePoseUpdated.t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relPoseR = rightToLeftGtRot\n",
    "relPoseTr = rightToLeftGtTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractROI(image, roi):\n",
    "    x, y, w, h = roi\n",
    "    return image[y : y + h, x : x + w]\n",
    "\n",
    "\n",
    "def rectifyStereo(\n",
    "    imgLeft,\n",
    "    imgRight,\n",
    "    intrinsicsLeft,\n",
    "    distortionLeft,\n",
    "    intrinsicsRight,\n",
    "    distortionRight,\n",
    "    rightToLeftR,\n",
    "    rightToLeftTrans,\n",
    "):\n",
    "\n",
    "    imgShape = imgLeft.shape[::-1]\n",
    "    print(imgShape)\n",
    "    rectifyRes = cv2.stereoRectify(\n",
    "        intrinsicsLeft,\n",
    "        distortionLeft,\n",
    "        intrinsicsRight,\n",
    "        distortionRight,\n",
    "        imgShape,\n",
    "        rightToLeftR,\n",
    "        rightToLeftTrans,\n",
    "    )\n",
    "\n",
    "    Rleft, Rright, Pleft, Pright, Q, roiLeft, roiRight = rectifyRes\n",
    "    print(roiLeft)\n",
    "    print(roiRight)\n",
    "    mapxLeft, mapyLeft = cv2.initUndistortRectifyMap(\n",
    "        intrinsicsLeft, distortionLeft, Rleft, Pleft, imgShape, cv2.CV_32FC1\n",
    "    )\n",
    "\n",
    "    mapxRight, mapyRight = cv2.initUndistortRectifyMap(\n",
    "        intrinsicsRight, distortionRight, Rright, Pright, imgShape, cv2.CV_32FC1\n",
    "    )\n",
    "\n",
    "    remapedLeft = cv2.remap(\n",
    "        imgLeft, mapxLeft, mapyLeft, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT\n",
    "    )\n",
    "    remapedRight = cv2.remap(\n",
    "        imgRight, mapxRight, mapyRight, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT\n",
    "    )\n",
    "\n",
    "    return remapedLeft, remapedRight\n",
    "\n",
    "\n",
    "print(relPoseR)\n",
    "print(relPoseTr)\n",
    "\n",
    "remapedLeft, remapedRight = rectifyStereo(\n",
    "    img1,\n",
    "    img2,\n",
    "    intrinsicsLeft,\n",
    "    distortionLeft,\n",
    "    intrinsicsRight,\n",
    "    distortionRight,\n",
    "    relPoseR,\n",
    "    relPoseTr,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCVImagesHorizontal([remapedLeft, remapedRight], True)\n",
    "PlotCameras([np.identity(3), relPoseR], [np.zeros((3)), relPoseTr])\n",
    "# PlotCameras([relPoseR], [relPoseTr])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('luxonis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33852ab07cff4f91becbc7beb8adcf124fd9b1ff2b365712e97bf8343f583684"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
